{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model.perceptron import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = np.genfromtxt(\"data/x_train.txt\")\n",
    "Y = np.genfromtxt(\"data/y_train.txt\")\n",
    "\n",
    "X_submission = np.genfromtxt(\"data/x_test.txt\")\n",
    "\n",
    "xtr, xte, ytr, yte = ml.splitData(X, Y, 0.75)\n",
    "\n",
    "n_folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 AUC of Training Data 0.500547261103\n",
      "Saving Results.\n"
     ]
    }
   ],
   "source": [
    "k = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "# after testing ks, found that 3 works the best\n",
    "# n_neighs = 3\n",
    "\n",
    "X, Y = ml.shuffleData(X,Y)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X, Y)\n",
    "yha = knn.predict_proba(X_submission)[0:,1]\n",
    "print(i, \"AUC of Training Data\", metrics.roc_auc_score(Y, yha))\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Saving Results.\")\n",
    "tmp = np.vstack([range(0, len(yha)), yha]).T\n",
    "np.savetxt(fname='knn.csv', X=tmp, fmt='%d, %0.2f', header='ID,Prob1', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  AUC :  0.606374195455\n",
      "2  AUC :  0.587166766609\n",
      "3  AUC :  0.578756826554\n",
      "4  AUC :  0.577866129551\n",
      "5  AUC :  0.595884331785\n",
      "6  AUC :  0.590903556653\n",
      "7  AUC :  0.602237887452\n",
      "8  AUC :  0.602845635947\n",
      "9  AUC :  0.605458793316\n",
      "10  AUC :  0.609862811012\n",
      "11  AUC :  0.614330048043\n",
      "12  AUC :  0.620181211266\n",
      "13  AUC :  0.624873596984\n",
      "14  AUC :  0.626535857967\n",
      "15  AUC :  0.63212966562\n",
      "16  AUC :  0.632743946054\n",
      "17  AUC :  0.637610191184\n",
      "18  AUC :  0.638471458804\n",
      "19  AUC :  0.641209535953\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    dt_stump = DecisionTreeClassifier(max_depth=i) #, min_samples_leaf=1) AUC :  0.597725685282\n",
    "    dt_stump.fit(xtr, ytr)\n",
    "    print(i, \" AUC : \",  metrics.roc_auc_score(yte, dt_stump.predict(xte)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg  roc :  0.573358700905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X, Y)\n",
    "\n",
    "logreg_yha = LogReg.predict(X)\n",
    "\n",
    "print(\"Log Reg  roc : \", metrics.roc_auc_score(Y, logreg_yha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "1  Ada  roc :  0.599082347648\n",
      "2  Ada  roc :  0.610880367175\n",
      "3  Ada  roc :  0.625808746306\n",
      "4  Ada  roc :  0.645105898815\n",
      "5  Ada  roc :  0.657367091295\n",
      "6  Ada  roc :  0.676674477783\n",
      "7  Ada  roc :  0.704768180203\n",
      "8  Ada  roc :  0.73223079933\n",
      "9  Ada  roc :  0.767757239354\n"
     ]
    }
   ],
   "source": [
    "print(\"starting\")\n",
    "for i in range(1,10):\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=i))\n",
    "    ada.fit(X, Y)\n",
    "\n",
    "    ada_yha = ada.predict(X)\n",
    "\n",
    "    ada_auc = metrics.roc_auc_score(Y, ada_yha)\n",
    "\n",
    "    print(i, \" Ada  roc : \", ada_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "for i in range(1,21):\n",
    "    gbc = GradientBoostingClassifier(max_depth=i)\n",
    "    gbc.fit(xtr, ytr)\n",
    "    gbc_yha = gbc.predict(xte)\n",
    "\n",
    "    gbc_auc = metrics.roc_auc_score(yte, gbc_yha)\n",
    "\n",
    "    print(i, \" gbc  roc : \", gbc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_xtr = np.zeros((ada_yha.shape[0], 3))\n",
    "\n",
    "tot_xtr[:,0] = knn_yha\n",
    "tot_xtr[:,1] = ada_yha\n",
    "tot_xtr[:,2] = gbc_yha\n",
    "\n",
    "y_submission = np.average(tot_xtr, axis=1, weights=[knn_auc, ada_auc, gbc_auc])\n",
    "\n",
    "tot_acc = metrics.roc_auc_score(yte, y_submission)\n",
    "\n",
    "print(\"all  roc : \", tot_acc)\n",
    "\n",
    "print(\"Saving Results.\")\n",
    "tmp = np.vstack([range(0, len(y_submission)), y_submission]).T\n",
    "np.savetxt(fname='submission.csv', X=tmp, fmt='%d, %0.2f', header='ID,Prob1', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n",
      "0 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "Fold  0\n",
      "  AUC =  0.696541623114\n",
      "Fold  1\n",
      "  AUC =  0.693617349124\n",
      "        Total AUC  0.728292177567\n",
      "1 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Fold  0\n",
      "  AUC =  0.675343785011\n",
      "Fold  1\n",
      "  AUC =  0.679155974813\n",
      "        Total AUC  0.679207812092\n",
      "2 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=6,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=0.5, verbose=0,\n",
      "              warm_start=False)\n",
      "Fold  0\n",
      "  AUC =  0.696436112309\n",
      "Fold  1\n",
      "  AUC =  0.702981909827\n",
      "        Total AUC  0.701187893931\n",
      "\n",
      "Blending.\n",
      "TOT  roc :  0.744523961443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "np.random.seed(0)  # seed to shuffle the train set\n",
    "\n",
    "\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "skf = list(StratifiedKFold(ytr, n_folds))\n",
    "\n",
    "clfs = [KNeighborsClassifier(n_neighbors=7),\n",
    "        AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)]\n",
    "\n",
    "print(\"Creating train and test sets for blending.\")\n",
    "\n",
    "dataset_blend_train = np.zeros((xtr.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((xte.shape[0], len(clfs)))\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    print(j, clf)\n",
    "    dataset_blend_test_j = np.zeros((xte.shape[0], len(skf)))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print(\"Fold \", i)\n",
    "        X_train = xtr[train]\n",
    "        Y_train = ytr[train]\n",
    "        X_test = xtr[test]\n",
    "        Y_test = ytr[test]\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        print(\"  AUC = \", metrics.roc_auc_score(Y_test, y_submission))\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(xte)[:, 1]\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print(\"        Total AUC \", metrics.roc_auc_score(yte, dataset_blend_test[:,j]))\n",
    "\n",
    "print()\n",
    "print(\"Blending.\")\n",
    "clf = LogisticRegression()\n",
    "clf.fit(dataset_blend_train, ytr)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "\n",
    "print(\"TOT  roc : \", metrics.roc_auc_score(yte, y_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Saving Results.\")\n",
    "tmp = np.vstack([range(0, len(dataset_blend_train)), dataset_blend_train]).T\n",
    "np.savetxt(fname='train.csv', X=tmp) #, fmt='%d, %0.2f', header='ID,Prob1', comments=''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Linear stretch of predictions to [0,1]\")\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "print(\"Saving Results.\")\n",
    "tmp = np.vstack([range(0, len(y_submission)), y_submission]).T\n",
    "np.savetxt(fname='submission.csv', X=tmp, fmt='%d, %0.2f', header='ID,Prob1', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
